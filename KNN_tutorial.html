<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>KNN</title>
  <link rel="stylesheet" href="https://stackedit.io/style.css" />
</head>

<body class="stackedit">
  <div class="stackedit__html"><h3 id="h2-id5knnh2"></h3><h2 id="5">KNN</h2>
<p align="center">
	  <img src="https://kevinzakka.github.io/assets/knn/teaser.png">
</p>
<ul>
<li><a href="#51">什么是 k 近邻算法</a></li>
<li><a href="#52">核心思想：K 近邻</a></li>
<li><a href="#53">K的影响</a></li>
<li><a href="https://zg104.github.io/KNN">Python代码示例：Sklearn &amp; Scratch</a></li>
<li><a href="#54">KNN的优缺点</a></li>
<li><a href="#55">改进</a></li>
<li><a href="#56">KNN面经和其他资料</a></li>
<li><a href="#57">小结</a></li>
</ul>
<h3 id="span-id51什么是-k-近邻算法span"><strong><span id="51">什么是 k 近邻算法</span></strong></h3>
<p>我们都已经熟悉了用 <span class="katex--inline"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathdefault" style="margin-right: 0.07847em;">X</span></span></span></span></span> 来表示特征（feature）和 <span class="katex--inline"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.19444em;"></span><span class="mord mathdefault" style="margin-right: 0.03588em;">y</span></span></span></span></span> 来表示目标（target），KNN 作为一个<strong>监督性学习算法</strong>，也就是我们有一个带有目标结果的数据集 <code>(X,y)</code>，并且我们想要研究他们其中的关系，也就是习得一个方程 <span class="katex--inline"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>h</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">h(x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathdefault">h</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span></span></span></span></span> 从而能用 <span class="katex--inline"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathdefault" style="margin-right: 0.07847em;">X</span></span></span></span></span> 来预测 <span class="katex--inline"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.19444em;"></span><span class="mord mathdefault" style="margin-right: 0.03588em;">y</span></span></span></span></span>。</p>
<p><span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>h</mi><mo>:</mo><mi>X</mi><mo>→</mo><mi>y</mi></mrow><annotation encoding="application/x-tex">h: X \rarr y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.69444em; vertical-align: 0em;"></span><span class="mord mathdefault">h</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathdefault" style="margin-right: 0.07847em;">X</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.19444em;"></span><span class="mord mathdefault" style="margin-right: 0.03588em;">y</span></span></span></span></span></span></p>
<p>KNN 分类器也是一种  <strong>non parametric</strong>  并且  <strong>instance-based</strong> 算法.</p>
<ul>
<li><strong>Non-parametric</strong>  说明它没有对函数 <span class="katex--inline"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>h</mi></mrow><annotation encoding="application/x-tex">h</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.69444em; vertical-align: 0em;"></span><span class="mord mathdefault">h</span></span></span></span></span> 做出任何明确的假设，从而避免了对数据的分布进行错误建模的危险。例如，假设我们的数据是高度非高斯分布的，但是我们选择的学习模型采用高斯形式（LDA），那么结果将会非常不如人意。</li>
<li><strong>Instance-based</strong>  说明我们的算法没有真正的学习模型。而是选择记忆所训练的实例，随后将其用作预测阶段的 “知识”。具体来说，这意味着仅当对我们的数据库进行查询时（即当我们要求它预测给定输入的标签时），该算法才会使用训练的实例给出答案。</li>
</ul>
<p>值得注意的是，KNN的最小的训练阶段不仅要花费一个 <strong>“内存成本”</strong>（因为我们必须在测试期间存储一个巨大数据集）还要一个**“计算成本”**（因为对给定观察值进行分类需要消耗整个数据组）。实际上，这是不可取的。</p>
<h3 id="span-id52核心思想：k-近邻span"><strong><span id="52">核心思想：K 近邻</span></strong></h3>
<p>在进行分类时，K近邻算法本质上归结为在给定 “看不见” 的 K 个最相似实例之间根据<strong>少数服从多数</strong>来表决（所以也称为<font color="red">投票算法</font>）。</p>
<p>如何定义相似度呢？我们根据两个数据点之间的距离度量来定义相似性。经常选用欧几里得距离来定义：</p>
<p><span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>d</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><msup><mi>x</mi><mo mathvariant="normal">′</mo></msup><mo stretchy="false">)</mo><mo>=</mo><msqrt><mrow><msup><mrow><mo fence="true">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo>−</mo><msubsup><mi>x</mi><mn>1</mn><mo mathvariant="normal">′</mo></msubsup><mo fence="true">)</mo></mrow><mn>2</mn></msup><mo>+</mo><mo>…</mo><mo>+</mo><msup><mrow><mo fence="true">(</mo><msub><mi>x</mi><mi>n</mi></msub><mo>−</mo><msubsup><mi>x</mi><mi>n</mi><mo mathvariant="normal">′</mo></msubsup><mo fence="true">)</mo></mrow><mn>2</mn></msup></mrow></msqrt></mrow><annotation encoding="application/x-tex">d(x, x') = \sqrt{\left(x_1 - x'_1 \right)^2 + \dotsc + \left(x_n - x'_n \right)^2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 1.05189em; vertical-align: -0.25em;"></span><span class="mord mathdefault">d</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.801892em;"><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1.84em; vertical-align: -0.462275em;"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.37773em;"><span class="svg-align" style="top: -3.8em;"><span class="pstrut" style="height: 3.8em;"></span><span class="mord" style="padding-left: 1em;"><span class="minner"><span class="minner"><span class="mopen delimcenter" style="top: 0em;">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.733692em;"><span class="" style="top: -2.43369em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span><span class="" style="top: -3.0448em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.266308em;"><span class=""></span></span></span></span></span></span><span class="mclose delimcenter" style="top: 0em;">)</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.954008em;"><span class="" style="top: -3.2029em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="minner">…</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="minner"><span class="minner"><span class="mopen delimcenter" style="top: 0em;">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.151392em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.677892em;"><span class="" style="top: -2.453em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span><span class="" style="top: -2.989em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.247em;"><span class=""></span></span></span></span></span></span><span class="mclose delimcenter" style="top: 0em;">)</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.954008em;"><span class="" style="top: -3.2029em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span><span class="" style="top: -3.33772em;"><span class="pstrut" style="height: 3.8em;"></span><span class="hide-tail" style="min-width: 1.02em; height: 1.88em;"><svg width="400em" height="1.8800000000000001em" viewBox="0 0 400000 1944" preserveAspectRatio="xMinYMin slice"><path d="M1001,80H400000v40H1013.1s-83.4,268,-264.1,840c-180.7,
572,-277,876.3,-289,913c-4.7,4.7,-12.7,7,-24,7s-12,0,-12,0c-1.3,-3.3,-3.7,-11.7,
-7,-25c-35.3,-125.3,-106.7,-373.3,-214,-744c-10,12,-21,25,-33,39s-32,39,-32,39
c-6,-5.3,-15,-14,-27,-26s25,-30,25,-30c26.7,-32.7,52,-63,76,-91s52,-60,52,-60
s208,722,208,722c56,-175.3,126.3,-397.3,211,-666c84.7,-268.7,153.8,-488.2,207.5,
-658.5c53.7,-170.3,84.5,-266.8,92.5,-289.5c4,-6.7,10,-10,18,-10z
M1001 80H400000v40H1013z"></path></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.462275em;"><span class=""></span></span></span></span></span></span></span></span></span></span></p>
<p>但是也有其他的选择例如：Manhattan、Chebyshev以及Hamming 距离。</p>
<p>给定一个正整数 K、一个未知的观测值 <span class="katex--inline"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.43056em; vertical-align: 0em;"></span><span class="mord mathdefault">x</span></span></span></span></span> 和一个衡量具体的方法 <span class="katex--inline"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>d</mi></mrow><annotation encoding="application/x-tex">d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.69444em; vertical-align: 0em;"></span><span class="mord mathdefault">d</span></span></span></span></span>，KNN 通过下列步骤进行分类：</p>
<ul>
<li>
<p>它跑遍整个数据集计算 <span class="katex--inline"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.43056em; vertical-align: 0em;"></span><span class="mord mathdefault">x</span></span></span></span></span> 和每个训练集观测值之间的距离。我们将训练数据集中最接近 <span class="katex--inline"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.43056em; vertical-align: 0em;"></span><span class="mord mathdefault">x</span></span></span></span></span> 的 K 个点称为集合 <span class="katex--inline"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathdefault">A</span></span></span></span></span>。<strong>注意，为了防止出现平局情况，K 通常是奇数</strong>。</p>
</li>
<li>
<p>接下来，它估计每个类别的条件概率，即具有给定类别标签的集合 <span class="katex--inline"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathdefault">A</span></span></span></span></span> 中点的比例。（注意 <span class="katex--inline"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>I</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">I(x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathdefault" style="margin-right: 0.07847em;">I</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span></span></span></span></span> 是个 indicator 函数，其参数 <span class="katex--inline"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.43056em; vertical-align: 0em;"></span><span class="mord mathdefault">x</span></span></span></span></span> 为 true 时返回 1，否则为 0）</p>
</li>
</ul>
<p><span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>y</mi><mo>=</mo><mi>j</mi><mi mathvariant="normal">∣</mi><mi>X</mi><mo>=</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mi>K</mi></mfrac><munder><mo>∑</mo><mrow><mi>i</mi><mo>∈</mo><mi mathvariant="script">A</mi></mrow></munder><mi>I</mi><mo stretchy="false">(</mo><msup><mi>y</mi><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msup><mo>=</mo><mi>j</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(y = j | X = x) = \frac{1}{K} \sum_{i \in \mathcal{A}} I(y^{(i)} = j)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathdefault" style="margin-right: 0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right: 0.03588em;">y</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathdefault" style="margin-right: 0.05724em;">j</span><span class="mord">∣</span><span class="mord mathdefault" style="margin-right: 0.07847em;">X</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 2.64315em; vertical-align: -1.32171em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.32144em;"><span class="" style="top: -2.314em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.07153em;">K</span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.677em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.686em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.05001em;"><span class="" style="top: -1.85566em; margin-left: 0em;"><span class="pstrut" style="height: 3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">∈</span><span class="mord mtight"><span class="mord mathcal mtight">A</span></span></span></span></span><span class="" style="top: -3.05em;"><span class="pstrut" style="height: 3.05em;"></span><span class=""><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 1.32171em;"><span class=""></span></span></span></span></span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord mathdefault" style="margin-right: 0.07847em;">I</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.03588em;">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.938em;"><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight">i</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathdefault" style="margin-right: 0.05724em;">j</span><span class="mclose">)</span></span></span></span></span></span></p>
<p>最后，我们输入的 <span class="katex--inline"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.43056em; vertical-align: 0em;"></span><span class="mord mathdefault">x</span></span></span></span></span> 根据最大的概率被分到对应的类别中。</p>
<blockquote>
<p>KNN searches the memorized training observations for the K instances that most closely resemble the new instance and assigns to it the their most common class.</p>
</blockquote>
<h3 id="span-id53k的影响span"><strong><span id="53">K的影响</span></strong></h3>
<p>那么现在，KNN 算法你应该了解了，但是关于 K 的选取还是很重要的，类似于其他的机器学习算法，K 是一个超参数，是用来控制决策边界的形状的。</p>
<p>当 <strong>K 较小</strong>时，我们将 “眼光” 局限在给定预测的区域，并对我们的分类器对整体分布“视而不见”，它将具有<strong>低偏差但高方差</strong>的性质（也就是<strong>overfitting</strong>）。在图形上，决策边界将更加<strong>参差不齐</strong>。</p>
<p>另一方面，较大的 K 表示每个预测情况中的平均 “选民” 更多（也就是我们更偏重全局的考虑，每次考虑的数据点更多，模型有更强的泛化能力），因此对异常值的适应性更高。较大的 K 值将具有较平滑的决策边界，这意味着<strong>方差较小，但偏差增加</strong>（<strong>K 过大会 underfitting</strong>）</p>
<center class="half">  <img src="https://kevinzakka.github.io/assets/knn/1nn.png" width="400" height="380/"><img src=" https://kevinzakka.github.io/assets/knn/20nn.png" width="400" height="380/">  </center>
<h3 id="span-id54knn的优缺点span"><strong><span id="54">KNN的优缺点</span></strong></h3>
<ul>
<li>
<p><strong>优点</strong></p>
<ul>
<li>简单易懂</li>
<li>没有数据分布的假设条件</li>
<li>对多类别分类的情况一样好用</li>
</ul>
</li>
<li>
<p><strong>缺点</strong></p>
<ul>
<li>计算量大，大数据情况使用起来效率低</li>
<li>对于偏分布的数据效果很差，假如一类数据出现频率极高，就会严重压制其他类别，在投票时，我们就会忽略他们的存在</li>
<li>高维数据表现不好，高维情况下，距离的远近变得模糊</li>
</ul>
</li>
</ul>
<h3 id="span-id55改进span"><strong><span id="55">改进</span></strong></h3>
<ul>
<li>改进偏分布的一种简单有效的方法是用 <strong>“加权投票”（weighed voting）</strong>。 K个邻居中每个邻居的类别乘以与从该点到给定测试点的距离的倒数成比例的权重。这确保了较近的邻居比较远的邻居对最终投票的贡献更大</li>
<li><strong>改变衡量距离的方法</strong></li>
<li>对**数据归一化（normalize）**使距离的概念更明显</li>
<li><strong>降维</strong></li>
<li><strong>近似最近邻</strong>（例如使用 <strong>k-d树</strong> 存储训练观测值）可用于减少测试时间。但是这个方法在高维（20+）上往往表现不佳。如果维度过高，可尝试用<strong>区域敏感哈希（LHS）</strong>。</li>
</ul>
<h3 id="span-id56knn面经和其他资料span"><strong><span id="56">KNN面经和其他资料</span></strong></h3>
<ul>
<li>
<p>面经</p>
<ul>
<li><a href="https://www.analyticsvidhya.com/blog/2017/09/30-questions-test-k-nearest-neighbors-algorithm/">30 Questions to test a data scientist on K-Nearest Neighbors (kNN) Algorithm</a></li>
<li><a href="https://medium.com/@cornell_data/interview-case-study-1-sampling-methods-and-parameter-changes-4799c580aa42">Interview Case Study #1: The Statistics Of KNN Parameter Optimization</a></li>
<li><a href="https://www.cnblogs.com/xueyunqing/p/10281656.html">KNN面经</a></li>
</ul>
</li>
<li>
<p>其他资料</p>
<ul>
<li><a href="https://cs231n.github.io/classification/#nn">Stanfords <strong>CS231n</strong> notes on KNN</a></li>
<li><a href="https://scikit-learn.org/stable/modules/neighbors.html">Scikit-learn’s documentation for KNN</a></li>
<li><a href="https://www.cnblogs.com/pinard/p/6061661.html">KNN小结-刘建平</a></li>
</ul>
</li>
</ul>
<h3 id="span-id57小结span"><strong><span id="57">小结</span></strong></h3>
<p>K近邻法（k-nearest neighbors,KNN）是一种很基本的机器学习方法了，在我们平常的生活中也会不自主的应用。比如，我们判断一个人的人品，只需要观察他来往最密切的几个人的人品好坏就可以得出了。这里就运用了KNN的思想。KNN方法既可以做分类，也可以做回归，这点和决策树算法相同。</p>
</div>
</body>

</html>
